M1$certified_num[M1$certified == "no"] = 0
c.tree1 <- rpart(certified_num ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.002))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.001, which decrease the criterion to split data.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
#Using the rpart package generate a classification tree predicting certified from the other variables in the M1 data frame.
M1$certified_num[M1$certified == "yes"] = 1
M1$certified_num[M1$certified == "no"] = 0
c.tree1 <- rpart(certified_num ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.003))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.001, which decrease the criterion to split data.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
#Using the rpart package generate a classification tree predicting certified from the other variables in the M1 data frame.
M1$certified_num[M1$certified == "yes"] = 1
M1$certified_num[M1$certified == "no"] = 0
c.tree1 <- rpart(certified_num ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.004))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.001, which decrease the criterion to split data.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
#Using the rpart package generate a classification tree predicting certified from the other variables in the M1 data frame.
M1$certified_num[M1$certified == "yes"] = 1
M1$certified_num[M1$certified == "no"] = 0
c.tree1 <- rpart(certified_num ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.005))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.001, which decrease the criterion to split data.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
#Using the rpart package generate a classification tree predicting certified from the other variables in the M1 data frame.
M1$certified_num[M1$certified == "yes"] = 1
M1$certified_num[M1$certified == "no"] = 0
c.tree1 <- rpart(certified_num ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.0045))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.001, which decrease the criterion to split data.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
#Using the rpart package generate a classification tree predicting certified from the other variables in the M1 data frame.
M1$certified_num[M1$certified == "yes"] = 1
M1$certified_num[M1$certified == "no"] = 0
c.tree1 <- rpart(certified_num ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.0042))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.001, which decrease the criterion to split data.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
#Using the rpart package generate a classification tree predicting certified from the other variables in the M1 data frame.
M1$certified_num[M1$certified == "yes"] = 1
M1$certified_num[M1$certified == "no"] = 0
c.tree1 <- rpart(certified_num ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.002))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.001, which decrease the criterion to split data.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Certified: 1 - YES, 0 - NO")
c.tree2 <- prune(c.tree1, cp = 0.047739)
plot(c.tree2)
post(c.tree2, file = "tree2.ps", title = "MOOC") #This creates a pdf image of the tree
c.tree2 <- prune(c.tree1, cp = 0.0047739)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.0042739)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.0043)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.0044)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.0045)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00448)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00445)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00448)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00446)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00445)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.004455)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.004458)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00445)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
printcp(c.tree2)
c.tree1 <- rpart(certified_num ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.002))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
c.tree2 <- prune(c.tree1, cp = 0.004453)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.004457)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.004455)
printcp(c.tree2)
M1$certified_num[M1$certified == "yes"] = 1
M1$certified_num[M1$certified == "no"] = 0
c.tree1 <- rpart(certified_num ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, cp=0.002))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, cp=0.002))
printcp(c.tree1)
knitr::opts_chunk$set(echo = TRUE)
library(rpart)
#Upload the data sets MOOC1.csv and MOOC2.csv
M1 <- read.csv("MOOC1.csv")
M2 <- read.csv("MOOC2.csv")
#Using the rpart package generate a classification tree predicting certified from the other variables in the M1 data frame.
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, cp=0.002))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Certified: 1 - YES, 0 - NO")
c.tree2 <- prune(c.tree1, cp = 0.0044555)
printcp(c.tree2)
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(cp=0.002))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(cp=0.002))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Certified: 1 - YES, 0 - NO")
c.tree2 <- prune(c.tree1, cp = 0.047739)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.047739)
printcp(c.tree2)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.0047739)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.003)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.004)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.0045)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00447)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00443)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00442)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.0044)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.0043)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00435)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00437)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.00436)
printcp(c.tree2)
c.tree2 <- prune(c.tree1, cp = 0.004355)
printcp(c.tree2)
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(cp=0.001))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Certified: 1 - YES, 0 - NO")
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(cp=0.0001))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Certified: 1 - YES, 0 - NO")
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.0001))
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.0001))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
c.tree1 <- rpart(certified ~ forum.posts + grade + assignment, method="class", data=M1, control=rpart.control(minsplit=2, minbucket=1, cp=0.0001))
# Here, when using the defalt rpart setting, it cannot generate "leaves" and lead to "fit is not a tree, just a root" error. So I modified the fit setting to cp=0.002, which decrease the criterion to split data and also generate a number of branches.
#Check the results from the classifcation tree using the printcp() command
printcp(c.tree1)
#Plot your tree
plot(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Certified: 1 - YES, 0 - NO")
c.tree2 <- prune(c.tree1, cp = 0.00392157)
printcp(c.tree2)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
post(c.tree2, file = "tree2.ps", title = "MOOC") #This creates a pdf image of the tree
c.tree2 <- prune(c.tree1, cp = 0.00392157)
printcp(c.tree2)
#Visualize this tree and compare it to the one you generated earlier
plot(c.tree2)
post(c.tree2, file = "tree2.ps", title = "MOOC") #This creates a pdf image of the tree
M2$predict1 <- predict(c.tree1, M2, type = "class")
M2$predict2 <- predict(c.tree2, M2, type = "class")
table(M2$certified, M2$predict1)
table(M2$certified, M2$predict2)
setwd("../assignment7-haidexs/")
predict
knitr::opts_chunk$set(echo = TRUE)
D1 = read.csv('online.data.csv')
View(D1)
library(reshape2)
library(plotly)
hp <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=2,colour="white")
ggplotly()
hp <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1,colour="white")
ggplotly()
hp <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1,colour="white")
hp + facet_grid(level.up, scales="free", space="free")
hp + facet_grid(D1$level.up, scales="free", space="free")
hp + facet_grid(~level.up, scales="free", space="free")
hp + facet_grid(~level.up, scales="free")
ggplotly()
hp + facet_grid(~level.up)
hp <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1,colour="white")
hp + facet_grid(~level.up)
hp <- ggplot(D1, aes(x=pre.test.score)) + geom_histogram(binwidth=0.1,colour="white")
hp + facet_grid(~level.up)
hp <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1,colour="white")
hp + facet_grid(~level.up)
hp <- ggplot(D1, aes(x=pre.test.score)) + geom_histogram(binwidth=0.1,colour="white")
hp + facet_grid(~level.up)
hp <- ggplot(D1, aes(x=messages)) + geom_histogram(binwidth=0.1,colour="white")
hp + facet_grid(~level.up)
hp <- ggplot(D1, aes(x=forum.posts)) + geom_histogram(binwidth=0.1,colour="white")
hp + facet_grid(~level.up)
hp <- ggplot(D1, aes(x=av.assignment.score)) + geom_histogram(binwidth=0.1,colour="white")
hp + facet_grid(~level.up)
hp <- ggplot(D1, aes(x=post.test.score)) + ggplot(D1, aes(x=pre.test.score)) + geom_histogram(binwidth=0.1,colour="white")
hp <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1,colour="white") + facet_grid(~level.up)
#Start by creating histograms of the distributions for all variables (#HINT: look up "facet" in the ggplot documentation)
hp1 <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1,colour="white") + facet_grid(~level.up)
hp2 <- ggplot(D1, aes(x=pre.test.score)) + geom_histogram(binwidth=0.1,colour="white") + facet_grid(~level.up)
hp3 <- ggplot(D1, aes(x=messages)) + geom_histogram(binwidth=5,colour="white") + facet_grid(~level.up)
hp4 <- ggplot(D1, aes(x=forum.posts)) + geom_histogram(binwidth=3,colour="white") + facet_grid(~level.up)
hp5 <- ggplot(D1, aes(x=av.assignment.score)) + geom_histogram(binwidth=0.05,colour="white") + facet_grid(~level.up)
multiplot(p1, p2, p3, p4, p5, cols = 3)
library(ggplot2)
multiplot(p1, p2, p3, p4, p5, cols = 3)
library(reshape2)
library(plotly)
library(ggplot2)
install.packages("scater")
source("https://bioconductor.org/biocLite.R")
biocLite("scater")
library(scater)
multiplot(p1, p2, p3, p4, p5, cols = 3)
multiplot(hp1, hp2, hp3, hp4, hp5, cols = 3)
hp1 <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1,colour="black") + facet_grid(~level.up)
multiplot(hp1, hp2, hp3, hp4, hp5, cols = 3)
hp1 <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1) + facet_grid(~level.up)
hp2 <- ggplot(D1, aes(x=pre.test.score)) + geom_histogram(binwidth=0.1,colour="white") + facet_grid(~level.up)
hp3 <- ggplot(D1, aes(x=messages)) + geom_histogram(binwidth=10,colour="white") + facet_grid(~level.up)
hp4 <- ggplot(D1, aes(x=forum.posts)) + geom_histogram(binwidth=3,colour="white") + facet_grid(~level.up)
hp5 <- ggplot(D1, aes(x=av.assignment.score)) + geom_histogram(binwidth=0.05,colour="white") + facet_grid(~level.up)
multiplot(hp1, hp2, hp3, hp4, hp5, cols = 3)
hp1 <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1,colour="white") + facet_grid(~level.up)
hp2 <- ggplot(D1, aes(x=pre.test.score)) + geom_histogram(binwidth=0.1,colour="white") + facet_grid(~level.up)
hp3 <- ggplot(D1, aes(x=messages)) + geom_histogram(binwidth=10,colour="white") + facet_grid(~level.up)
hp4 <- ggplot(D1, aes(x=forum.posts)) + geom_histogram(binwidth=3,colour="white") + facet_grid(~level.up)
hp5 <- ggplot(D1, aes(x=av.assignment.score)) + geom_histogram(binwidth=0.05,colour="white") + facet_grid(~level.up)
multiplot(hp1, hp2, hp3, hp4, hp5, cols = 3)
COR <- cor(D1)
D2 = select(D1, -c('id', 'level.up'))
D2 = select(D1, -c("id", "level.up"))
D2 = select(D1, -c(id, level.up))
COR <- cor(D1)
COR <- cor(D2)
corrplot(COR, order="AOE", method="circle", tl.pos="lt", type="upper",
tl.col="black", tl.cex=0.6, tl.srt=45,
addCoef.col="black", addCoefasPercent = TRUE,
sig.level=0.50, insig = "blank")
D2 = select(D1, -c(id))
D2$level.up[D2$level.up == "no"] = 0
D2$level.up[D2$level.up == "yes"] = 1
View(D1)
View(D2)
D2$level.up[as.character(D2$level.up) == "no"] = 0
as.character(D1$level.up)
D2$level.up = as.character(D2$level.up)
D1$level.up
D2 = select(D1, -c(id))
D2$level.up = as.character(D2$level.up)
D2$level.up[D2$level.up == "no"] = 0
D2$level.up[D2$level.up == "yes"] = 1
D2$level.up = as.numeric(D2$level.up)
COR <- cor(D2)
corrplot(COR, order="AOE", method="circle", tl.pos="lt", type="upper",
tl.col="black", tl.cex=0.6, tl.srt=45,
addCoef.col="black", addCoefasPercent = TRUE,
sig.level=0.50, insig = "blank")
# Start by creating histograms of the distributions for all variables (#HINT: look up "facet" in the ggplot documentation)
# I plot them in one figure with "multiplot" from package "scater"
hp1 <- ggplot(D1, aes(x=post.test.score)) + geom_histogram(binwidth=0.1,colour="white") + facet_grid(~level.up)
hp2 <- ggplot(D1, aes(x=pre.test.score)) + geom_histogram(binwidth=0.1,colour="white") + facet_grid(~level.up)
hp3 <- ggplot(D1, aes(x=messages)) + geom_histogram(binwidth=10,colour="white") + facet_grid(~level.up)
hp4 <- ggplot(D1, aes(x=forum.posts)) + geom_histogram(binwidth=3,colour="white") + facet_grid(~level.up)
hp5 <- ggplot(D1, aes(x=av.assignment.score)) + geom_histogram(binwidth=0.05,colour="white") + facet_grid(~level.up)
multiplot(hp1, hp2, hp3, hp4, hp5, cols = 3)
# Then visualize the relationships between variables with correlogram plot after removing id and converting level.up to numbers.
D2 = select(D1, -c(id))
D2$level.up = as.character(D2$level.up)
D2$level.up[D2$level.up == "no"] = 0
D2$level.up[D2$level.up == "yes"] = 1
D2$level.up = as.numeric(D2$level.up)
COR <- cor(D2)
corrplot(COR, order="AOE", method="circle", tl.pos="lt", type="upper",
tl.col="black", tl.cex=0.6, tl.srt=45,
addCoef.col="black", addCoefasPercent = TRUE,
sig.level=0.50, insig = "blank")
c.tree1 <- rpart(level.up ~ messages + forum.posts + av.assignment.score + pre.test.score, method="class", data=D1)
printcp(c.tree1)
plot(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Certified: 1 - YES, 0 - NO")
plot(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Level up: 1 - YES, 0 - NO")
c.tree1 <- rpart(level.up ~ messages + forum.posts + av.assignment.score + pre.test.score, method="class", data=D1, control=rpart.control(minsplit=2, minbucket=1))
printcp(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Level up: 1 - YES, 0 - NO")
c.tree1 <- rpart(level.up ~ messages + forum.posts + av.assignment.score + pre.test.score, method="class", data=D1, control=rpart.control(minsplit=2, minbucket=1, cp=0.0001))
printcp(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Level up: 1 - YES, 0 - NO")
printcp(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Level up: 1 - YES, 0 - NO")
post(c.tree1, file = "tree.ps", title = "Level up: 1 - YES, 0 - NO")
D1$pred <- predict(rp, type = "prob")[,2]#Last class we used type = "class" which predicted the classification for us, this time we are using type = "prob" to see the probability that our classififcation is based on.
D1$pred <- predict(c,tree1, type = "prob")[,2]#Last class we used type = "class" which predicted the classification for us, this time we are using type = "prob" to see the probability that our classififcation is based on.
D1$pred <- predict(c.tree1, type = "prob")[,2]#Last class we used type = "class" which predicted the classification for us, this time we are using type = "prob" to see the probability that our classififcation is based on.
install.packages("ROCR")
library(ROCR)
pred.detail <- prediction(D1$pred, D1$level.up)
plot(performance(pred.detail, "tpr", "fpr"))
abline(0, 1, lty = 2)
c.tree1 <- rpart(level.up ~ messages + forum.posts + av.assignment.score + pre.test.score, method="class", data=D1, control=rpart.control(minsplit=2, minbucket=1))
#Plot and generate a CP table for your tree
printcp(c.tree1)
post(c.tree1, file = "tree.ps", title = "Level up: 1 - YES, 0 - NO")
D1$pred <- predict(c.tree1, type = "prob")[,2]#Last class we used type = "class" which predicted the classification for us, this time we are using type = "prob" to see the probability that our classififcation is based on.
#Plot the ROC curve
pred.detail <- prediction(D1$pred, D1$level.up)
plot(performance(pred.detail, "tpr", "fpr"))
abline(0, 1, lty = 2)
unlist(slot(performance(Pred2,"auc"), "y.values"))#Unlist liberates the AUC value from the "performance" object created by ROCR
unlist(slot(performance(pred.detail,"auc"), "y.values"))#Unlist liberates the AUC value from the "performance" object created by ROCR
c.tree1 <- rpart(level.up ~ messages + forum.posts + pre.test.score, method="class", data=D1, control=rpart.control(minsplit=2, minbucket=1))
#Plot and generate a CP table for your tree
printcp(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Level up: 1 - YES, 0 - NO")
#Generate a probability value that represents the probability that a student levels up based your classification tree
D1$pred <- predict(c.tree1, type = "prob")[,2]#Last class we used type = "class" which predicted the classification for us, this time we are using type = "prob" to see the probability that our classififcation is based on.
#Plot the ROC curve
pred.detail <- prediction(D1$pred, D1$level.up)
plot(performance(pred.detail, "tpr", "fpr"))
abline(0, 1, lty = 2)
#Calculate the Area Under the Curve
unlist(slot(performance(pred.detail,"auc"), "y.values"))#Unlist liberates the AUC value from the "performance" object created by ROCR
#Create a classification tree that predicts whether a student "levels up" in the online course using three variables of your choice (As we did last time, set all controls to their minimums)
c.tree1 <- rpart(level.up ~ messages + forum.posts + pre.test.score, method="class", data=D1, control=rpart.control(minsplit=2, minbucket=1))
#Plot and generate a CP table for your tree
printcp(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Level up: 1 - YES, 0 - NO")
#Generate a probability value that represents the probability that a student levels up based your classification tree
D1$pred <- predict(c.tree1, type = "prob")[,2]#Last class we used type = "class" which predicted the classification for us, this time we are using type = "prob" to see the probability that our classififcation is based on.
#Plot the ROC curve
pred.detail <- prediction(D1$pred, D1$level.up)
plot(performance(pred.detail, "tpr", "fpr"))
abline(0, 1, lty = 2)
#Calculate the Area Under the Curve
unlist(slot(performance(pred.detail,"auc"), "y.values"))#Unlist liberates the AUC value from the "performance" object created by ROCR
#Now repeat this process with average assignment score and post test score.
c.tree2 <- rpart(level.up ~ av.assignment.score + post.test.score, method="class", data=D1, control=rpart.control(minsplit=2, minbucket=1))
printcp(c.tree2)
post(c.tree2, file = "tree2.ps", title = "Level up: 1 - YES, 0 - NO")
D1$pred2 <- predict(c.tree2, type = "prob")[,2]
pred2.detail <- prediction(D1$pred2, D1$level.up)
plot(performance(pred2.detail, "tpr", "fpr"))
abline(0, 1, lty = 2)
unlist(slot(performance(pred2.detail,"auc"), "y.values"))
#Which one do you think was the better model? Why?
unlist(slot(performance(pred.detail,"auc"), "y.values"))
unlist(slot(performance(pred2.detail,"auc"), "y.values"))
#Create a classification tree that predicts whether a student "levels up" in the online course using three variables of your choice (As we did last time, set all controls to their minimums)
# Model 1, I use # of messages, # of forum posts and pre test score.
c.tree1 <- rpart(level.up ~ messages + forum.posts + pre.test.score, method="class", data=D1, control=rpart.control(minsplit=2, minbucket=1))
#Plot and generate a CP table for your tree
printcp(c.tree1)
post(c.tree1, file = "tree1.ps", title = "Level up: 1 - YES, 0 - NO")
#Generate a probability value that represents the probability that a student levels up based your classification tree
D1$pred <- predict(c.tree1, type = "prob")[,2]#Last class we used type = "class" which predicted the classification for us, this time we are using type = "prob" to see the probability that our classififcation is based on.
#Plot the ROC curve
pred.detail <- prediction(D1$pred, D1$level.up)
plot(performance(pred.detail, "tpr", "fpr"))
abline(0, 1, lty = 2)
#Calculate the Area Under the Curve
unlist(slot(performance(pred.detail,"auc"), "y.values"))#Unlist liberates the AUC value from the "performance" object created by ROCR
#Now repeat this process with average assignment score and post test score.
# Model 2, I use # of messages, # of forum posts and pre test score.
c.tree2 <- rpart(level.up ~ av.assignment.score + post.test.score, method="class", data=D1, control=rpart.control(minsplit=2, minbucket=1))
printcp(c.tree2)
post(c.tree2, file = "tree2.ps", title = "Level up: 1 - YES, 0 - NO")
D1$pred2 <- predict(c.tree2, type = "prob")[,2]
pred2.detail <- prediction(D1$pred2, D1$level.up)
plot(performance(pred2.detail, "tpr", "fpr"))
abline(0, 1, lty = 2)
D1$pred_int = 0
D1$pred_int[D1$pred >= 0.22] = 1
table(D1$pred_int, D1$level.up)
table1 <- table(D1$level.up, D1$threshold.pred1)
table1 <- table(D1$level.up, D1$pred_int)
matrix1 <- as.matrix(table1)
kappa(matrix1, exact = TRUE)/kappa(matrix1)
table1 = table(D1$pred_int, D1$level.up)
table2 <- table(D1$level.up, D1$pred_int)
tabel1
table1 = table(D1$pred_int, D1$level.up)
table1
table2 <- table(D1$level.up, D1$pred_int)
table2
kappa(matrix1, exact = TRUE)/kappa(matrix1)
m2 = as.matrix(table2)
kappa(m2, exact=TRUE)/kappa(m2)
table1
table[1,1]
table(1,1)
table1[1,1]
table1[2,2]
D1$accuracy.model1 <- (table1[1,1]+table[2,2])/1000
D1$accuracy.model1 <- (table1[1,1]+table1[2,2])/1000
table1[2,1]
D1$precision.model1 <- table1[2,2]/(table1[2,2]+table1[2,1])
D1$recall.model1 <- table1[2,2]/(table1[2,2]+table1[1,2])
matrix1 <- as.matrix(table1)
kappa(matrix1, exact = TRUE)/kappa(matrix1)
table1 <- table(D1$level.up, D1$pred_int)
#Convert to matrix
matrix1 <- as.matrix(table1)
#Calculate kappa
kappa(matrix1, exact = TRUE)/kappa(matrix1)
table1
threshod2 = 0.06
D1$pred_int_2 = 0
D1$pred_int_2[D1$pred >= threshod2] = 1
table1 = table(D1$pred_int_2, D1$level.up)
table1
unlist(slot(performance(pred.detail,"auc"), "y.values"))#Unlist liberates the AUC value from the "performance" object created by ROCR
pred.detail <- prediction(D1$pred, D1$level.up)
plot(performance(pred.detail, "tpr", "fpr"))
abline(0, 1, lty = 2)
threshod2 = 0.04
D1$pred_int_2 = 0
D1$pred_int_2[D1$pred >= threshod2] = 1
table1 = table(D1$pred_int_2, D1$level.up)
table1
threshod2 = 0.1
D1$pred_int_2 = 0
D1$pred_int_2[D1$pred >= threshod2] = 1
table1 = table(D1$pred_int_2, D1$level.up)
table1
threshod2 = 0.7
D1$pred_int_2 = 0
D1$pred_int_2[D1$pred >= threshod2] = 1
table1 = table(D1$pred_int_2, D1$level.up)
table1
threshod2 = 0.7
D1$pred_int_2 = 0
D1$pred_int_2[D1$pred >= threshod2] = 1
table2 = table(D1$pred_int_2, D1$level.up)
# Accuracy = correct predictions / total predictions
D1$accuracy.model2 <- (table2[1,1]+table2[2,2])/1000
# Precision = True Pos. / (True Pos. + False Pos.)
D1$precision.model2 <- table2[2,2]/(table2[2,2]+table2[2,1])
# Recall = True Pos. / (True Pos. + False Neg.)
D1$recall.model2 <- table2[2,2]/(table2[2,2]+table2[1,2])
#Finally, calculate Kappa for your model according to:
table2 <- table(D1$level.up, D1$pred_int_2)
#Convert to matrix
matrix2 <- as.matrix(table2)
#Calculate kappa
kappa(matrix2, exact = TRUE)/kappa(matrix2)
tabel1
table1
table2
unique(D1$accuracy.model1)
